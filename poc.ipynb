{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3b4e7e",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00aff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df49451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "class ShakespeareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        seq_len=256,\n",
    "        max_samples=None,\n",
    "        file_path=\"data/shakespeare.txt\",\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Read Shakespeare text\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "\n",
    "        # Flatten to single sequence, tokeniz and reshape to (num_batches, seq_len) \n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        n_batches = len(tokens) // seq_len\n",
    "        self.sequences = torch.tensor(tokens[:n_batches * seq_len], dtype=torch.long).reshape(n_batches, seq_len)\n",
    "        if max_samples is not None:\n",
    "            self.sequences = self.sequences[:max_samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return {\"input_ids\": seq, \"labels\": seq}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c636a8",
   "metadata": {},
   "source": [
    "### Train GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e140e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Epoch 1: 0it [00:00, ?it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val loss: 0.35 | Sample: 'Hello, how are you?claveclaveclaveclaveclave caps caps caps caps caps'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "seq_len = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 1\n",
    "num_samples = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_llm = AutoModelForCausalLM.from_config(AutoConfig.from_pretrained(\"gpt2\"))\n",
    "dataset = ShakespeareDataset(tokenizer, seq_len=256, max_samples=num_samples)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_llm.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\", total=len(train_dataloader))\n",
    "    for batch in pbar:\n",
    "        output = model_llm(**batch)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model_llm.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            output = model_llm(**batch)\n",
    "            eval_loss += output.loss.item()\n",
    "    eval_loss /= (len(val_dataloader) * batch_size)\n",
    "\n",
    "    # Log\n",
    "    sample_input_ids = torch.tensor(tokenizer.encode(\"Hello, how are you?\"))\n",
    "    sample_text = tokenizer.decode(model_llm.generate(sample_input_ids.reshape(1, -1), max_length=16)[0])\n",
    "    print(f\"[Epoch {epoch+1}] Val loss: {eval_loss:.2f} | Sample: {repr(sample_text)}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098e76c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sample_input_ids = torch.tensor(tokenizer.encode(\"Hello, how are you?\"))\n",
    "sample_text = tokenizer.decode(model_llm.generate(sample_input_ids.reshape(1, -1), max_length=16)[0])\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model_llm.state_dict(),\n",
    "        \"val_loss\": eval_loss,\n",
    "    },\n",
    "    f\"checkpoints/gpt2-latest-dev.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f6062",
   "metadata": {},
   "source": [
    "### Train PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52a9fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338024 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any' | ids: tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597])\n",
      "' further, hear me speak.\\n\\n' | ids: tensor([2252,   11, 3285,  502, 2740,   13,  198,  198])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# # 1. Shakespeare dataset\n",
    "file_path = \"../data/shakespeare/main.txt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "seq_len = 8\n",
    "batch_size = 512\n",
    "max_samples = 2\n",
    "\n",
    "dataset = ShakespeareDataset(tokenizer, seq_len=seq_len, max_samples=max_samples)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# visualize\n",
    "for i in range(min(5, max_samples)):\n",
    "    print(f\"{repr(tokenizer.decode(dataset[i]['input_ids']))} | ids: {dataset[i]['input_ids']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef4284",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'train_gradient_descent' from 'spflow' (/Users/marawangamal/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mleaf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Scope\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_likelihood, train_gradient_descent\n\u001b[32m      8\u001b[39m torch.manual_seed(\u001b[32m0\u001b[39m)\n\u001b[32m     10\u001b[39m num_features = seq_len\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'train_gradient_descent' from 'spflow' (/Users/marawangamal/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from spflow.modules.rat import RatSPN\n",
    "from spflow.modules.leaf import Categorical\n",
    "from spflow.meta import Scope\n",
    "from spflow import log_likelihood\n",
    "from spflow.learn import train_gradient_descent\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_features = seq_len\n",
    "K = len(tokenizer) \n",
    "batch_size = 256\n",
    "\n",
    "scope = Scope(list(range(num_features)))\n",
    "\n",
    "leaf_layer = Categorical(\n",
    "    scope=scope,\n",
    "    out_channels=4,\n",
    "    num_repetitions=2,\n",
    "    K=K,\n",
    ")\n",
    "\n",
    "model_spn = RatSPN(\n",
    "    leaf_modules=[leaf_layer],\n",
    "    n_root_nodes=1,\n",
    "    n_region_nodes=8,\n",
    "    num_repetitions=2,\n",
    "    depth=3,\n",
    "    outer_product=False,\n",
    ")\n",
    "\n",
    "train_gradient_descent(model_spn, dataloader, epochs=20, lr=0.1)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model_spn.parameters(), lr=1e-2)\n",
    "# n_epochs = 2_000\n",
    "# log_every = 1000\n",
    "# for epoch in range(n_epochs):\n",
    "#     for step, batch in tqdm(enumerate(dataloader), leave=False, total=len(dataloader)):\n",
    "#         optimizer.zero_grad()\n",
    "#         data = batch['input_ids']\n",
    "#         ll = log_likelihood(model_spn, data)          # (B,)\n",
    "#         loss = -ll.mean()                         # NLL\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     if epoch % log_every == 0:\n",
    "#         print(f\"[Epoch {epoch}] Loss {loss.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9af818ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model_spn.state_dict(),\n",
    "        \"eval_loss\": eval_loss,\n",
    "    },\n",
    "    f\"checkpoints/rat-latest-dev.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11b26a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 0 expected index [4, 1, 8, 1, 1] to be no larger than self [2, 1, 8, 1, 2] apart from dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m evidence = data.clone().float()\n\u001b[32m      8\u001b[39m evidence[:\u001b[32m2\u001b[39m] = torch.nan\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43msample_with_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_spn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# evidence = X_tensor[0]\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# evidence[:32] = torch.nan\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# plt.imshow(evidence.reshape(8,8), cmap=\"gray\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# plt.imshow(samples.reshape(8,8), cmap=\"gray\")\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/module.py:259\u001b[39m, in \u001b[36msample_with_evidence\u001b[39m\u001b[34m(module, evidence, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Perform forward log_likelihood pass to populate dispatch context cache for possible conditional samples\u001b[39;00m\n\u001b[32m    257\u001b[39m log_likelihood(module, evidence, check_support=check_support, dispatch_ctx=dispatch_ctx)\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/rat/rat_spn.py:265\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(rat_spn, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     sample_root = rat_spn.root_node\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/rat/rat_mixing_layer.py:160\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(module, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    157\u001b[39m sampling_ctx.repetition_idx = repetition_idx\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Sample from input module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/sum.py:261\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(module, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    257\u001b[39m     indices = indices.view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).expand(\n\u001b[32m    258\u001b[39m         -\u001b[32m1\u001b[39m, logits.shape[\u001b[32m1\u001b[39m], in_channels_total, logits.shape[\u001b[32m3\u001b[39m], -\u001b[32m1\u001b[39m\n\u001b[32m    259\u001b[39m     )\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# Gather the logits based on the repetition indices\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     logits = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    264\u001b[39m     logits = module.logits.unsqueeze(\u001b[32m0\u001b[39m).expand(sampling_ctx.channel_index.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Size does not match at dimension 0 expected index [4, 1, 8, 1, 1] to be no larger than self [2, 1, 8, 1, 2] apart from dimension 4"
     ]
    }
   ],
   "source": [
    "# Sample use of PC\n",
    "from spflow import sample, sample_with_evidence\n",
    "# # MPE:\n",
    "# sample(model_spn, 1, is_mpe=True)\n",
    "\n",
    "# CON:\n",
    "# evidence = data.clone().float()\n",
    "# evidence[:2] = torch.nan\n",
    "# sample_with_evidence(model_spn, evidence)\n",
    "\n",
    "# evidence = X_tensor[0]\n",
    "# evidence[:32] = torch.nan\n",
    "# plt.imshow(evidence.reshape(8,8), cmap=\"gray\")\n",
    "# plt.show()\n",
    "# evidence = evidence.unsqueeze(0)\n",
    "# print(evidence.shape)\n",
    "# samples = sample_with_evidence(rat, evidence)\n",
    "# plt.imshow(samples.reshape(8,8), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dbee2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24093ba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 1 expected index [1, 8, 8, 1] to be no larger than self [1, 1, 8, 1] apart from dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m seq[\u001b[32m5\u001b[39m:] = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Sample from SPN conditional on the rest\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m samples = \u001b[43mspn_sample_with_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_spn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1, seq_len)\u001b[39;00m\n\u001b[32m     61\u001b[39m samples = samples[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# drop batch dim\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal:\u001b[39m\u001b[33m\"\u001b[39m, data[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mspn_sample_with_evidence\u001b[39m\u001b[34m(model_spn, evidence)\u001b[39m\n\u001b[32m     34\u001b[39m channel_index = torch.zeros((B, out_features), dtype=torch.int64, device=device)\n\u001b[32m     36\u001b[39m sampling_ctx = SamplingContext(\n\u001b[32m     37\u001b[39m     channel_index=channel_index,\n\u001b[32m     38\u001b[39m     mask=mask,\n\u001b[32m     39\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m samples_float = \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_spn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m samples_long = samples_float.round().to(torch.long)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m samples_long\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/rat/rat_spn.py:265\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(rat_spn, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     sample_root = rat_spn.root_node\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/rat/rat_mixing_layer.py:160\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(module, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    157\u001b[39m sampling_ctx.repetition_idx = repetition_idx\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Sample from input module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_mpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdispatch_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/meta/dispatch/substitutable.py:85\u001b[39m, in \u001b[36msubstitutable.<locals>.substitutable_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.funcs:\n\u001b[32m     83\u001b[39m     _f = dispatch_ctx.funcs[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/llm-mpe/.venv/lib/python3.13/site-packages/spflow/modules/sum.py:270\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(module, data, is_mpe, check_support, dispatch_ctx, sampling_ctx)\u001b[39m\n\u001b[32m    268\u001b[39m idxs = idxs.expand(-\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, in_channels_total, -\u001b[32m1\u001b[39m)\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Gather the logits based on the channel indices\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m logits = \u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m3\u001b[39m)\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# check if evidence is given\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    274\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlog_likelihood\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dispatch_ctx.cache\n\u001b[32m    275\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m dispatch_ctx.cache[\u001b[33m\"\u001b[39m\u001b[33mlog_likelihood\u001b[39m\u001b[33m\"\u001b[39m][module.inputs] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    276\u001b[39m ):\n\u001b[32m    277\u001b[39m     \u001b[38;5;66;03m# get the log likelihoods from the cache\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Size does not match at dimension 1 expected index [1, 8, 8, 1] to be no larger than self [1, 1, 8, 1] apart from dimension 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spflow import sample\n",
    "from spflow.meta import SamplingContext\n",
    "\n",
    "def spn_sample_with_evidence(model_spn: RatSPN, evidence: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    evidence:\n",
    "      - shape (seq_len,) or (B, seq_len)\n",
    "      - entries that are NaN will be sampled\n",
    "      - non-NaN entries are treated as clamped evidence\n",
    "\n",
    "    Returns:\n",
    "      samples: same shape, dtype long (token ids)\n",
    "    \"\"\"\n",
    "    device = next(model_spn.parameters()).device\n",
    "\n",
    "    # Make it (B, seq_len)\n",
    "    if evidence.dim() == 1:\n",
    "        evidence = evidence.unsqueeze(0)  # (1, seq_len)\n",
    "\n",
    "    # For categorical leaves we still use float here so we can hold NaNs\n",
    "    evidence = evidence.to(torch.float32).to(device)  # (B, seq_len)\n",
    "\n",
    "    B, out_features = evidence.shape\n",
    "\n",
    "    # mask == True -> sample here, mask == False -> keep evidence\n",
    "    mask = torch.isnan(evidence)  # (B, seq_len)\n",
    "\n",
    "    # If there is absolutely nothing to sample, just return the clamped evidence\n",
    "    if not mask.any():\n",
    "        return evidence.round().to(torch.long)\n",
    "\n",
    "    # All channels 0 (youâ€™re using out_channels=4 but we pick one repetition/channel)\n",
    "    channel_index = torch.zeros((B, out_features), dtype=torch.int64, device=device)\n",
    "\n",
    "    sampling_ctx = SamplingContext(\n",
    "        channel_index=channel_index,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "    samples_float = sample(model_spn, evidence, sampling_ctx=sampling_ctx)\n",
    "    samples_long = samples_float.round().to(torch.long)\n",
    "\n",
    "    return samples_long\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_spn.eval()\n",
    "data = batch[\"input_ids\"]          # (B, seq_len), dtype long\n",
    "\n",
    "# Pick a single sequence\n",
    "seq = data[0].clone()              # (seq_len,)\n",
    "\n",
    "# Mask some positions, e.g. positions 10..19\n",
    "seq = seq.to(torch.float32)\n",
    "seq[5:] = float(\"nan\")\n",
    "\n",
    "# Sample from SPN conditional on the rest\n",
    "samples = spn_sample_with_evidence(model_spn, seq)  # (1, seq_len)\n",
    "samples = samples[0]  # drop batch dim\n",
    "\n",
    "print(\"Original:\", data[0])\n",
    "print(\"Evidence with NaNs:\", seq)\n",
    "print(\"Sampled:\", samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2065be9",
   "metadata": {},
   "source": [
    "### Max decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e47f9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LogitsProcessor\n",
    "\n",
    "class HeuristicProcessor(LogitsProcessor):\n",
    "    def __init__(self, model_pc):\n",
    "        super().__init__()\n",
    "        self.model_pc = model_pc\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # does nothing\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdd163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL greedy: 29.62\n",
      "NLL heuristic: 29.62\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LogitsProcessorList\n",
    "\n",
    "\n",
    "model_llm_state_dict = torch.load(\"checkpoints/gpt2-latest-dev.pth\")[\"model_state_dict\"]\n",
    "model_llm.load_state_dict(model_llm_state_dict)\n",
    "\n",
    "model_spn_state_dict = torch.load(\"checkpoints/rat-latest-dev.pth\")[\"model_state_dict\"]\n",
    "model_spn.load_state_dict(model_spn_state_dict)\n",
    "\n",
    "model_llm.eval()\n",
    "model_spn.eval()\n",
    "\n",
    "sample_input_ids = torch.tensor(tokenizer.encode(\"Hello, how are you?\"))\n",
    "\n",
    "\n",
    "# Generate text (greedy)\n",
    "greedy_dict = model_llm.generate(sample_input_ids.reshape(1, -1), max_new_tokens=32, do_sample=False, output_scores=True, return_dict_in_generate=True)\n",
    "y_hat_greedy = torch.cat(\n",
    "    (sample_input_ids[1:].reshape(1, -1), greedy_dict['sequences'][:, :-1]),\n",
    "    dim=-1\n",
    ")\n",
    "nll_greedy = torch.cat(greedy_dict['scores'], dim=0).gather(dim=1, index=y_hat_greedy).sum()\n",
    "\n",
    "\n",
    "# Generate text (heuristic)\n",
    "processors = LogitsProcessorList([\n",
    "    HeuristicProcessor(model_spn)\n",
    "])\n",
    "heur_dict = model_llm.generate(\n",
    "    sample_input_ids.reshape(1, -1), \n",
    "    max_new_tokens=32, \n",
    "    do_sample=False, \n",
    "    output_scores=True, \n",
    "    return_dict_in_generate=True,\n",
    "    logits_processor=processors,\n",
    ")\n",
    "y_hat_heur = torch.cat(\n",
    "    (sample_input_ids[1:].reshape(1, -1), greedy_dict['sequences'][:, :-1]),\n",
    "    dim=-1\n",
    ")\n",
    "nll_heur = torch.cat(heur_dict['scores'], dim=0).gather(dim=1, index=y_hat_heur).sum()\n",
    "\n",
    "\n",
    "print(f\"NLL greedy: {nll_greedy.item():.2f}\")\n",
    "print(f\"NLL heuristic: {nll_heur.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb9d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
